<!-- question-type: prepare -->
### Exercise 1: Identifying Issues with Un-tidy Data

We'll start with the deliberately messy version of the ASX stock price data. 

```{r}
asx_prices_messy <- read_csv("data/asx_prices_messy.csv")

asx_prices_messy |> 
    select(gvkey, conm, price_2023, price_2023, 
           eps_2023, eps_2024) |>
    head(10)
```

**(a).** In what ways is this data frame not tidy? Be specific: which tidy‑data principles are violated?

**(b).** Suppose we want the average share price across 2023–2024:

$$
\text{avg_price_23_24} = 
\frac{\text{sum_prices_2023} + \text{sum_prices_2024}}
     {\text{count_firms_2023} + \text{count_firms_2024}}
$$
With this messy layout you will need to compute across columns. Fill in the blanks to compute the average share price.

```{r}
#| eval: false

asx_prices_messy |>
    summarise(
        # Sum the prices from the 2023 year
        sum_prices_2023   = sum(YOUR_CODE_HERE, na.rm = TRUE),
        # Sum the prices from the 2024 year
        sum_prices_2024   = sum(YOUR_CODE_HERE, na.rm = TRUE),
        # Count the number of firms with non missing
        # prices in 2023
        count_firms_2023 = sum(!is.na(price_2023)),
        # Count the number of firms with non missing
        # prices in 2024
        count_firms_2024 = sum(!is.na(price_2024))
    ) |>
    mutate(
        # Compute the total sum of prices across both years
        total_sum   = YOUR_CODE_HERE + YOUR_CODE_HERE,
        # Compute the total count of firms across both years
        total_count = count_firms_2023 + count_firms_2024
    ) |>
    mutate(
        # Manually compute the average
        avg_price_23_24 = YOUR_CODE_HERE / YOUR_CODE_HERE
    ) |> 
    select(avg_price_23_24)
```



**(c)** Explain why the approach we took in (b) won't scale as more years of data are added.

**(d)** Examining relationships between variables in a messy data frame can be especially tricky. Suppose we want to see whether share price and earnings per share are correlated in 2024. With this messy structure we must hard-code the year's columns:

```{r}
asx_prices_messy |>
    filter(!is.na(eps_2024)) |>
    ggplot(aes(x = eps_2024, y = price_2024)) +
    geom_point(alpha = 0.4) +
    geom_smooth(method = "lm", se = TRUE, color = "blue") +
    labs(
        title = "Share Price vs EPS (2024)",
        x = "Earnings per Share (EPS, 2024)",
        y = "Share Price (2024)"
    ) +
    ylim(-5, 300) + 
    theme_minimal()
```

What relationship do you see in 2024?
Why does this make sense economically (what are investors "buying" when they invest)?


**(e)**. Now imagine you also wanted to include 2023 in the same analysis. You do not implement code to add these data points — just explain the steps you'd need to take.

* Which additional columns would you need to reference in the data?
* How would your plotting code change?
* What problems do you foresee if you wanted to extend this further to 2019–2024?



<!-- BEGIN PROFILE:r-teaching-guide -->
::: {.content-visible when-profile="r-teaching-guide"}

::: {.teaching-block}

::: {.teaching-block-header}
Teaching Note
:::

::: {.teaching-block-body}

🎯 **Learning Objective** 
Students should:

- XXXXX

✅   **Core Concepts to Highlight**

List them here


💬 **Suggested In-Class Prompts** (if needed)

NA

📌 **Common Misunderstandings**

List as needed

:::

:::

:::
<!-- END PROFILE:r-teaching-guide -->

<!-- BEGIN PROFILE:r-solutions -->
::: {.content-visible when-profile="r-solutions" when-profile="r-teaching-guide"}

::: {.solution-block}

::: {.solution-block-header}
Solution
:::

::: {.solution-block-body}

**(a). Why this data frame is “messy”**

- Data is stored in column names: columns like `price_2020` or `eps_2023` contain values (years) that should instead appear in a variable column (e.g., `fyear`). This violates the principles that “column names are variables, not values” and "each value must have its own cell."

- Two variables are encoded in column names: each column like `price_2020` or `eps_2023` mixes the measure (price vs EPS) and the year (2020, 2023). This violates “each variable has its own column.”

- One observation is split across many columns: a single firm–year record is spread over separate columns for each year, rather than one row per firm–year. This violates “each observation (firm–year) has its own row.”

- Heterogeneous columns for the same concept: all the `price_*` columns represent the same variable (price) measured in different years, but they appear as many columns instead of one `price` column with a `fyear` identifier.

**(b)**.

```{r}
asx_prices_messy |>
    summarise(
        # Sum the prices from the 2023 year
        sum_prices_2023   = sum(price_2023, na.rm = TRUE),
        # Sum the prices from the 2024 year
        sum_prices_2024   = sum(price_2024, na.rm = TRUE),
        # Count the number of firms with non missing
        # prices in 2023
        count_firms_2023 = sum(!is.na(price_2023)),
        # Count the number of firms with non missing
        # prices in 2024
        count_firms_2024 = sum(!is.na(price_2024))
    ) |>
    mutate(
        # Compute the total sum of prices across both years
        total_sum   = sum_prices_2023 + sum_prices_2024,
        # Compute the total count of firms across both years
        total_count = count_firms_2023 + count_firms_2024
    ) |>
    mutate(
        # Manually compute the average
        avg_price_23_24 = total_sum / total_count
    ) |> 
    select(avg_price_23_24)
```

**(c)**.
The approach in (b) doesn't scale because each new year of data adds a new column (e.g., `price_2022`, `price_2023`), which requires manually updating the code in four different places: two sums and two counts. This becomes tedious and error-prone as the number of years grows.


**(d)**. 
In 2024, the plot shows a positive relationship between earnings per share (EPS) and share price. This makes sense because investors are generally willing to pay more for companies that earn more per share — higher earnings often signal better profitability, which increases a firm’s value.

Economically, this reflects the idea that when investors buy a share, they’re buying a claim on future earnings. So firms with higher EPS tend to attract more investor demand, pushing up their share price.

**(e)**. 

To include 2023 in the same analysis, you'd need to manually reference two more columns: eps_2023 and price_2023. You would then need to copy and adapt your plotting code to create a second scatterplot or combine the data in some custom way.

Your code would get much longer and harder to manage, especially if you wanted to compare more years (e.g., 2019–2024). For each new year, you'd have to:

* Add new x and y column references (e.g., eps_2022, price_2022)
* Manually stack or merge the data across years
* Repeat or complicate the plotting code

This shows how the column-based structure becomes inefficient and messy, making it hard to scale analyses or visualizations.
:::

:::

:::
<!-- END PROFILE:r-solutions -->
